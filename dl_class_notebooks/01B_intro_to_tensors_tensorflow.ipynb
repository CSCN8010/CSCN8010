{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Introduction to Tensors (Tensorflow)\n",
        "1. From: https://www.tensorflow.org/guide/tensor (retrieved from [Github](https://github.com/tensorflow/docs/blob/9bfffb91247233025892f2d293aa4d206c0ccad9/site/en/guide/tensor.ipynb)). Presented here according to the Apache 2.0 License\n",
        "2. See also: Chollet, p.26-47 (for definitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AL2hzxorJiWy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRK5-9EpYbzG"
      },
      "source": [
        "## Basics\n",
        "\n",
        "First, create some basic tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSHRFT6LJbxq"
      },
      "source": [
        "Here is a \"scalar\" or \"rank-0\" tensor . A scalar contains a single value, and no \"axes\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d5JcgLFR6gHv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
        "rank_0_tensor = tf.constant(4)\n",
        "print(rank_0_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdmPAn9fWYs5"
      },
      "source": [
        "A \"vector\" or \"rank-1\" tensor is like a list of values. A vector has one axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oZos8o_R6oE7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Let's make this a float tensor.\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "print(rank_1_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3IJG-ug_H4u"
      },
      "source": [
        "A \"matrix\" or \"rank-2\" tensor has two axes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cnOIA_xb6u0M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]])\n",
        "print(rank_2_tensor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "19m72qEPkfxi"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A scalar, shape: <code>[]</code></th>\n",
        "  <th>A vector, shape: <code>[3]</code></th>\n",
        "  <th>A matrix, shape: <code>[3, 2]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"../images/tensor/scalar.png\" alt=\"A scalar, the number 4\" />\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "   <img src=\"../images/tensor/vector.png\" alt=\"The line with 3 sections, each one containing a number.\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img src=\"../images/tensor/matrix.png\" alt=\"A 3x2 grid, with each cell containing a number.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fjFvzcn4_ehD"
      },
      "source": [
        "A rank 3 tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sesW7gw6JkXy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "rank_3_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "print(rank_3_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM2sTGIkoE3S"
      },
      "source": [
        "There are many ways you might visualize a tensor with more than two axes."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NFiYfNMMhDgL"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=3>A 3-axis tensor, shape: <code>[3, 2, 5]</code></th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"../images/tensor/3-axis_numpy.png\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img src=\"../images/tensor/3-axis_front.png\"/>\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "   <img src=\"../images/tensor/3-axis_block.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hnz19F0ocEKD"
      },
      "source": [
        "Tensors often contain floats and ints, but have many other types, including:\n",
        "\n",
        "* complex numbers\n",
        "* strings\n",
        "\n",
        "The base `tf.Tensor` class requires tensors to be \"rectangular\"---that is, along each axis, every element is the same size.  However, there are specialized types of tensors that can handle different shapes:\n",
        "\n",
        "* Ragged tensors\n",
        "* Sparse tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDC7OGeAIJr8"
      },
      "source": [
        "You can do basic math on tensors, including addition, element-wise multiplication, and matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-DTkjwDOIIDa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
        "\n",
        "print(tf.add(a, b), \"\\n\")\n",
        "print(tf.multiply(a, b), \"\\n\")\n",
        "print(tf.matmul(a, b), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2smoWeUz-N2q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(a + b, \"\\n\") # element-wise addition\n",
        "print(a * b, \"\\n\") # element-wise multiplication\n",
        "print(a @ b, \"\\n\") # matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3_vIAl2JPVc"
      },
      "source": [
        "Tensors are used in all kinds of operations (or \"Ops\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Gp4WUYzGIbnv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "tf.Tensor([1 0], shape=(2,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
        "\n",
        "# Find the largest value\n",
        "print(tf.reduce_max(c))\n",
        "# Find the index of the largest value\n",
        "print(tf.math.argmax(c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvSAbowVVuRr"
      },
      "source": [
        "## About shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkaBIqkTCcGY"
      },
      "source": [
        "Tensors have shapes.  Some vocabulary:\n",
        "\n",
        "* **Shape**: The length (number of elements) of each of the axes of a tensor.\n",
        "* **Rank**: Number of tensor axes.  A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
        "* **Axis** or **Dimension**: A particular dimension of a tensor.\n",
        "* **Size**: The total number of items in the tensor, the product of the shape vector's elements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOyG2tn8LhW"
      },
      "source": [
        "Tensors and `tf.TensorShape` objects have convenient properties for accessing these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RyD3yewUKdnK"
      },
      "outputs": [],
      "source": [
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZZW9ziq4og"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=2>A rank-4 tensor, shape: <code>[3, 2, 4, 5]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"../images/tensor/shape.png\" alt=\"A tensor shape is like a vector.\">\n",
        "    <td>\n",
        "<img src=\"../images/tensor/4-axis_block.png\" alt=\"A 4-axis tensor\">\n",
        "  </td>\n",
        "  </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MHm9vSqogsBk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type of every element: <dtype: 'float32'>\n",
            "Number of axes: 4\n",
            "Shape of tensor: (3, 2, 4, 5)\n",
            "Elements along axis 0 of tensor: 3\n",
            "Elements along the last axis of tensor: 5\n",
            "Total number of elements (3*2*4*5):  120\n"
          ]
        }
      ],
      "source": [
        "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZGZp_JOOPOv"
      },
      "source": [
        "(note that the `Tensor.ndim` and `Tensor.shape` attributes don't return `Tensor` objects. If you need a `Tensor` use the `tf.rank` or `tf.shape` function. This difference is subtle, but it can be important when building graphs (later))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ptq0-y6APCpD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.rank(rank_4_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HslrDOEBPICN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 2, 4, 5])>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.shape(rank_4_tensor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmE_Vx5JilS"
      },
      "source": [
        "While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<th>Typical axis order</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "<img src=\"../images/tensor/shape2.png\" alt=\"Keep track of what each axis is. A 4-axis tensor might be: Batch, Width, Height, Features\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPoVvJS75Bb"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "apOkCKqCZIZu"
      },
      "source": [
        "### Single-axis indexing\n",
        "\n",
        "TensorFlow follows standard Python indexing rules, similar to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings), and the basic rules for NumPy indexing.\n",
        "\n",
        "* indexes start at `0`\n",
        "* negative indices count backwards from the end\n",
        "* colons, `:`, are used for slices: `start:stop:step`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SQ-CrJxLXTIM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ]
        }
      ],
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQYYL56PXSak"
      },
      "source": [
        "Indexing with a scalar removes the axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n6tqHciOWMt5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First: 0\n",
            "Second: 1\n",
            "Last: 34\n"
          ]
        }
      ],
      "source": [
        "print(\"First:\", rank_1_tensor[0].numpy())\n",
        "print(\"Second:\", rank_1_tensor[1].numpy())\n",
        "print(\"Last:\", rank_1_tensor[-1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJLHU_a2XwpG"
      },
      "source": [
        "Indexing with a `:` slice keeps the axis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "giVPPcfQX-cu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
            "Before 4: [0 1 1 2]\n",
            "From 4 to the end: [ 3  5  8 13 21 34]\n",
            "From 2, before 7: [1 2 3 5 8]\n",
            "Every other item: [ 0  1  3  8 21]\n",
            "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
          ]
        }
      ],
      "source": [
        "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
        "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
        "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
        "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
        "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
        "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elDSxXi7X-Bh"
      },
      "source": [
        "### Multi-axis indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgk0uRUYZiai"
      },
      "source": [
        "Higher rank tensors are indexed by passing multiple indices.\n",
        "\n",
        "The exact same rules as in the single-axis case apply to each axis independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Tc5X_WlsZXmd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n"
          ]
        }
      ],
      "source": [
        "print(rank_2_tensor.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07U9vq5ipQk"
      },
      "source": [
        "Passing an integer for each index, the result is a scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PvILXc1PjqTM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "# Pull out a single value from a 2-rank tensor\n",
        "print(rank_2_tensor[1, 1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RLCzAOHjfEH"
      },
      "source": [
        "You can index using any combination of integers and slices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YTqNqsfJkJP_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Second row: [3 4]\n",
            "Second column: [2 4 6]\n",
            "Last row: [5 6]\n",
            "First item in last column: 2\n",
            "Skip the first row:\n",
            "[[3 4]\n",
            " [5 6]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get row and column tensors\n",
        "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
        "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
        "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
        "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
        "print(\"Skip the first row:\")\n",
        "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P45TwSUVSK6G"
      },
      "source": [
        "Here is an example with a 3-axis tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(rank_3_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GuLoMoCVSLxK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 4  9]\n",
            " [14 19]\n",
            " [24 29]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(rank_3_tensor[:, :, 4])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9NgmHq27TJOE"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<th colspan=2>Selecting the last feature across all locations in each example in the batch </th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "<img src=\"../images/tensor/index1.png\" alt=\"A 3x2x5 tensor with all the values at the index-4 of the last axis selected.\">\n",
        "  </td>\n",
        "      <td>\n",
        "<img src=\"../images/tensor/index2.png\" alt=\"The selected values packed into a 2-axis tensor.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpr7R0t4SVb0"
      },
      "source": [
        "## Manipulating Shapes\n",
        "\n",
        "Reshaping a tensor is of great utility. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EMeTtga5Wq8j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 1)\n"
          ]
        }
      ],
      "source": [
        "# Shape returns a `TensorShape` object that shows the size along each axis\n",
        "x = tf.constant([[1], [2], [3]])\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "38jc2RXziT3W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3, 1]\n"
          ]
        }
      ],
      "source": [
        "# You can convert this object into a Python list, too\n",
        "print(x.shape.as_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xRlHZMKYnF"
      },
      "source": [
        "You can reshape a tensor into a new shape. The `tf.reshape` operation is fast and cheap as the underlying data does not need to be duplicated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pa9JCgMLWy87"
      },
      "outputs": [],
      "source": [
        "# You can reshape a tensor to a new shape.\n",
        "# Note that you're passing in a list\n",
        "reshaped = tf.reshape(x, [1, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Mcq7iXOkW3LK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 1)\n",
            "(1, 3)\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "print(reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIB2tOkoVr6E"
      },
      "source": [
        "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7kMfM0RpUgI8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(rank_3_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcDtfQkJWzIx"
      },
      "source": [
        "If you flatten a tensor you can see what order it is laid out in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "COnHEPuaWDQp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
        "print(tf.reshape(rank_3_tensor, [-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJZRira2W--c"
      },
      "source": [
        "Typically the only reasonable use of `tf.reshape` is to combine or split adjacent axes (or add/remove `1`s).\n",
        "\n",
        "For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zP2Iqc7zWu_J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]\n",
            " [15 16 17 18 19]\n",
            " [20 21 22 23 24]\n",
            " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
        "print(tf.reshape(rank_3_tensor, [3, -1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZsZRUhihlDB"
      },
      "source": [
        "<table>\n",
        "<th colspan=3>\n",
        "Some good reshapes.\n",
        "</th>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"../images/tensor/reshape-before.png\" alt=\"A 3x2x5 tensor\">\n",
        "  </td>\n",
        "  <td>\n",
        "  <img src=\"../images/tensor/reshape-good1.png\" alt=\"The same data reshaped to (3x2)x5\">\n",
        "  </td>\n",
        "  <td>\n",
        "<img src=\"../images/tensor/reshape-good2.png\" alt=\"The same data reshaped to 3x(2x5)\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOcRxDC3jNIU"
      },
      "source": [
        "Reshaping will \"work\" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.\n",
        "\n",
        "Swapping axes in `tf.reshape` does not work; you need `tf.transpose` for that. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "I9qDL_8u7cBH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
            "\n",
            "InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
          ]
        }
      ],
      "source": [
        "# Bad examples: don't do this\n",
        "\n",
        "# You can't reorder axes with reshape.\n",
        "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\") \n",
        "\n",
        "# This is a mess\n",
        "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
        "\n",
        "# This doesn't work at all\n",
        "try:\n",
        "  tf.reshape(rank_3_tensor, [7, -1])\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qTM9-5eh68oo"
      },
      "source": [
        "<table>\n",
        "<th colspan=3>\n",
        "Some bad reshapes.\n",
        "</th>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"../images/tensor/reshape-bad.png\" alt=\"You can't reorder axes, use tf.transpose for that\">\n",
        "  </td>\n",
        "  <td>\n",
        "<img src=\"../images/tensor/reshape-bad4.png\" alt=\"Anything that mixes the slices of data together is probably wrong.\">\n",
        "  </td>\n",
        "  <td>\n",
        "<img src=\"../images/tensor/reshape-bad2.png\" alt=\"The new shape must fit exactly.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N9r90BvHCbTt"
      },
      "source": [
        "You may run across not-fully-specified shapes. Either the shape contains a `None` (an axis-length is unknown) or the whole shape is `None` (the rank of the tensor is unknown).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDmFtFM7k0R2"
      },
      "source": [
        "## More on `DTypes`\n",
        "\n",
        "To inspect a `tf.Tensor`'s data type use the `Tensor.dtype` property.\n",
        "\n",
        "When creating a `tf.Tensor` from a Python object you may optionally specify the datatype.\n",
        "\n",
        "If you don't, TensorFlow chooses a datatype that can represent your data. TensorFlow converts Python integers to `tf.int32` and Python floating point numbers to `tf.float32`. Otherwise TensorFlow uses the same rules NumPy uses when converting to arrays.\n",
        "\n",
        "You can cast from type to type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5mSTDWbelUvu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
          ]
        }
      ],
      "source": [
        "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
        "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
        "# Now, cast to an uint8 and lose the decimal precision\n",
        "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
        "print(the_u8_tensor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s1yBlJsVlFSu"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "Broadcasting is a concept borrowed from the [equivalent feature in NumPy](https://numpy.org/doc/stable/user/basics.broadcasting.html).  In short, under certain conditions, smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\n",
        "\n",
        "The simplest and most common case is when you attempt to multiply or add a tensor to a scalar.  In that case, the scalar is broadcast to be the same shape as the other argument. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "P8sypqmagHQN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0SBoR6voWcb"
      },
      "source": [
        "Likewise, axes with length 1 can be stretched out to match the other arguments.  Both arguments can be stretched in the same computation.\n",
        "\n",
        "In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is `[4]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6sGmkPg3XANr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1]\n",
            " [2]\n",
            " [3]], shape=(3, 1), dtype=int32) \n",
            "\n",
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# These are the same computations\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(1, 5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(tf.multiply(x, y))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t_7sh-EUYLrE"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A broadcasted add: a <code>[3, 1]</code> times a <code>[1, 4]</code> gives a <code>[3,4]</code> </th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"../images/tensor/broadcasting.png\" alt=\"Adding a 3x1 matrix to a 4x1 matrix results in a 3x4 matrix\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V3KgSJcKDRz"
      },
      "source": [
        "Here is the same operation without broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "elrF6v63igY8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14KobqYu85gi"
      },
      "source": [
        "Most of the time, broadcasting is both time and space efficient, as the broadcast operation never materializes the expanded tensors in memory.  \n",
        "\n",
        "You see what broadcasting looks like using `tf.broadcast_to`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GW2Q59_r8hZ6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]], shape=(3, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The section below is based on the following tutorial:\n",
        "# https://github.com/tensorflow/docs/blob/6cc2e627ebe212ad2d19604ec4e6e5588221aef0/site/en/tutorials/customization/basics.ipynb\n",
        "# See also: https://www.tensorflow.org/tutorials/customization/basics\n",
        "# Presented here according to the Apache 2.0 License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNP8yTRfu_X"
      },
      "source": [
        "## GPU acceleration\n",
        "\n",
        "Many TensorFlow operations are accelerated using the GPU for computation. Without any annotations, TensorFlow automatically decides whether to use the GPU or CPU for an operationâ€”copying the tensor between CPU and GPU memory, if necessary. Tensors produced by an operation are typically backed by the memory of the device on which the operation executed. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "cellView": "code",
        "id": "3Twf_Rw-gQFM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available GPUs (empty list if no GPU is available): \n",
            "[]\n",
            "Is the Tensor on GPU #0:  \n",
            "False\n"
          ]
        }
      ],
      "source": [
        "x = tf.random.uniform([3, 3])\n",
        "\n",
        "print(\"Available GPUs (empty list if no GPU is available): \"),\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "print(\"Is the Tensor on GPU #0:  \"),\n",
        "print(x.device.endswith('GPU:0'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpgYzgVXW2Ud"
      },
      "source": [
        "### Device names\n",
        "\n",
        "The `Tensor.device` property provides a fully qualified string name of the device hosting the contents of the tensor. This name encodes many details, such as an identifier of the network address of the host on which this program is executing and the device within that host. This is required for distributed execution of a TensorFlow program. The string ends with `GPU:<N>` if the tensor is placed on the `N`-th GPU on the host."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWZQCimzuqyP"
      },
      "source": [
        "### Explicit device placement\n",
        "\n",
        "In TensorFlow, *placement* refers to how individual operations are assigned (placed on) a device for execution. As mentioned, when there is no explicit guidance provided, TensorFlow automatically decides which device to execute an operation and copies tensors to that device, if needed.\n",
        "\n",
        "However, TensorFlow operations can be explicitly placed on specific devices using the `tf.device` context manager. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RjkNZTuauy-Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On CPU:\n",
            "10 loops: 162.83ms\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def time_matmul(x):\n",
        "  start = time.time()\n",
        "  for loop in range(10):\n",
        "    tf.linalg.matmul(x, x)\n",
        "\n",
        "  result = time.time()-start\n",
        "\n",
        "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
        "\n",
        "# Force execution on CPU\n",
        "print(\"On CPU:\")\n",
        "with tf.device(\"CPU:0\"):\n",
        "  x = tf.random.uniform([1000, 1000])\n",
        "  assert x.device.endswith(\"CPU:0\")\n",
        "  time_matmul(x)\n",
        "\n",
        "# Force execution on GPU #0 if available\n",
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "  print(\"On GPU:\")\n",
        "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
        "    x = tf.random.uniform([1000, 1000])\n",
        "    assert x.device.endswith(\"GPU:0\")\n",
        "    time_matmul(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "tensor.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "tensorflow_cpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
