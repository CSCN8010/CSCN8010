{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensors (PyTorch)\n",
    "This notebook introduces PyTorch's Tensors.\n",
    "\n",
    "For further reading about PyTorch's tensors here are some useful resources:\n",
    "1. https://pytorch.org/docs/stable/tensors.html (retrieved 2022-12-24, [Github](https://github.com/pytorch/tutorials/blob/d5161086e7277f10c68dd44914f8925fda62f399/beginner_source/blitz/tensor_tutorial.py))\n",
    "2. https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html (retrieved 2022-12-24, [Github](https://github.com/pytorch/tutorials/blob/c2115df8003e6a3aeeb327441ff4d8389576d6f0/beginner_source/introyt/tensors_deeper_tutorial.py))\n",
    "3. https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html (retrieved from [Github](https://github.com/pytorch/tutorials/blob/d5161086e7277f10c68dd44914f8925fda62f399/beginner_source/blitz/tensor_tutorial.py))\n",
    "4. Chollet, p.26-47 (for definitions and a Tensorflow implementation)\n",
    "\n",
    "The images were taken from: https://www.tensorflow.org/guide/tensor (retrieved from [Github](https://github.com/tensorflow/docs/blob/9bfffb91247233025892f2d293aa4d206c0ccad9/site/en/guide/tensor.ipynb)). Presented here according to the Apache 2.0 License.\n",
    "Matrix Multiplication example were taken from Geron's Linear Algebra appendix ([Github](https://github.com/ageron/handson-ml3/blob/f122f5ac70636214aeea04c8ee3541d8ef59f715/math_linear_algebra.ipynb)). Presented here according to the Apache 2.0 License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Importance of Tensors for Deep Learning\n",
    "\n",
    "In deep learning, tensors are the basic unit of data. Tensors represents both:\n",
    "* _Data_ such as the input, output and intermediate representations of a model\n",
    "* The _Parameters_ of the model, such as weights and biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor - a Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eBPw8e8vrsom"
   },
   "source": [
    "**Tensors are multi-dimensional arrays with a uniform type (called a `dtype`).**\n",
    "\n",
    "The most obvious differences between NumPy arrays and PyTorch and Tensorflow tensors are:\n",
    "\n",
    "1. Tensors can be backed by accelerator memory (like GPU).\n",
    "2. Tensors can have non-numerical data types\n",
    "3. Tensors can be ragged (non-rectangular)\n",
    "4. Tensors have a different set of operations (extended, generally speaking)\n",
    "5. Tensorflow's Tensors are immutable. In Tensorflow, all tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one. On the other hand, PyTorch tensors are mutable, just like in NumPy.\n",
    "\n",
    "\n",
    "The mathematical definition of a tensor ([Wikipedia](https://en.wikipedia.org/wiki/Tensor)) and the tensor implementation in PyTorch and Tensorflow are similar, but not exactly equivalent. The tensor of the DL frameworks is an _object_ (e.g. in Python), that is based on the mathematical concept, but it extends it, and can break it on occasion. Some of the notable differences are that tensors in DL frameworks can be ragged (non-rectangular), and include operations such as broadcasting which are not natively defined as part of the mathematical concept. They can also include 'programmatic' attributes and methods (such as device placement, that are obviously not part of the mathematical definition)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Shape and Rank of a Tensor\n",
    "\n",
    "* Rank (dimensionality) - the number of axes in a tensor.\n",
    "* Shape - a tuple containing the number of elements in each axis (for rectangular tensors).\n",
    "\n",
    "_Note: The term dimensionality can denote either the number of entries along a specific axis or the number of axes in a tensor, which can be confusing at times._\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th>Rank 0 (a scalar)</th>\n",
    "  <th>Rank 1 (a vector)</th>\n",
    "  <th>Rank 2 (a matrix)</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"../images/tensor/scalar.png\" alt=\"Rank 0 (a scalar)\" />\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "   <img src=\"../images/tensor/vector.png\" alt=\"Rank 1 (a vector)\"/>\n",
    "  </td>\n",
    "  <td>\n",
    "   <img src=\"../images/tensor/matrix.png\" alt=\"Rank 2 (a matrix)\">\n",
    "  </td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=3>A rank-3 tensor (represented in three different ways) </th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"../images/tensor/3-axis_numpy.png\"/>\n",
    "  </td>\n",
    "  <td>\n",
    "   <img src=\"../images/tensor/3-axis_front.png\"/>\n",
    "  </td>\n",
    "\n",
    "  <td>\n",
    "   <img src=\"../images/tensor/3-axis_block.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=2>A rank-4 tensor, shape: <code>[3, 2, 4, 5]</code></th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "<img src=\"../images/tensor/shape.png\" alt=\"A tensor shape is like a vector.\">\n",
    "    <td>\n",
    "<img src=\"../images/tensor/4-axis_block.png\" alt=\"A 4-axis tensor\">\n",
    "  </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Typical axis order</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\n",
    "<img src=\"../images/tensor/shape2.png\" alt=\"Keep track of what each axis is. A 4-axis tensor might be: Batch, Width, Height, Features\">\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import helpers as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\n",
      "pyTorch version: 2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# check the version of Python and PyTorch\n",
    "h.print_python_version()\n",
    "h.print_pytorch_version()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Tensors\n",
    "Let's see how to initialize tensors using PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiailize a rank-1 tensor (vector)\n",
    "We start with an initialization of a tensor based on a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    1\n",
      "Shape        (2,)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PyTorch tensor is a class. Here it is of the type `torch.Tensor`. As in any Python class, it has attributes and methods associated with it. \n",
    "* Tip: Look into the function definition of `h.printing_tensor_info` to see the Tensor's methods and attributes used to display the values above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, each tensor has a `device` associated with it. By default (for constructors such as `torch.tensor`) this device is the CPU. It can also be a GPU. To check for the device a tensor is associated with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device.type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a vector with a single element. Notice the tensor-dimensionality and shape of this tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    1\n",
      "Shape        (1,)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.,])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it has a single element, this is still a vector (a vector is defined by having rank=1 - a single dimension, `tensor.dim() == 1`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a rank-0 tensor (scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    0\n",
      "Shape        ()\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.5)\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a rank-2 tensor (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    2\n",
      "Shape        (2, 2)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., 2.],[3., 4.]])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a rank-3 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.]],\n",
      "\n",
      "        [[5.],\n",
      "         [6.]]])\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    3\n",
      "Shape        (3, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [[1.,],[2.,]],\n",
    "    [[3.,],[4.,]],\n",
    "    [[5.,],[6.,]],\n",
    "    ])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicitly defining the tensor's data type\n",
    "The default data type for the constructor `torch.tensor` is `torch.float32`. This is the data type of each of the elements in the tensors. A tensor can have only a single data type. \n",
    "To set a different dtype for the elements, we can simply add it as an argument when calling the constructor:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], dtype=torch.float64)\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float64\n",
      "Dimension    1\n",
      "Shape        (1,)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], dtype=torch.double)\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "We have been using the word 'constructor' to describe `torch.tensor`. In addition, you might have seen (or might see) defining a constant tensor by `torch.Tensor` instead of `torch.tensor`. Let's take a deeper look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    1\n",
      "Shape        (1,)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1.])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], dtype=torch.int32)\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.int32\n",
      "Dimension    1\n",
      "Shape        (1,)\n"
     ]
    }
   ],
   "source": [
    "x = torch.IntTensor([1])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor` and `torch.Tensor` are not the same. `torch.tensor` is a constructor and `torch.Tensor` is an alias for the default tensor type (`torch.FloatTensor`). As can be seen below, the first is a function, while the second is a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'builtin_function_or_method'>\n",
      "<class 'torch._C._TensorMeta'>\n"
     ]
    }
   ],
   "source": [
    "print(type(torch.tensor))\n",
    "print(type(torch.Tensor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all the tensor classes available in PyTorch can be found here: https://pytorch.org/docs/stable/tensors.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesor Indexing, Slicing and Assignments\n",
    "A subset of elements can be accessed by indexing and slicing a tensor. In addition, in PyTorch (but not in Tensorflow) it is possible to assign a new value to some elements within the tensor.\n",
    "\n",
    "PyTorch and Tensorflow follow standard Python indexing rules, similar to [indexing a list or a string in Python](https://docs.python.org/3/tutorial/introduction.html#strings), and the basic rules for NumPy indexing.\n",
    "\n",
    "* indexes start at `0`\n",
    "* negative indices count backwards from the end\n",
    "* colons, `:`, are used for slices: `start:stop:step`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rank 2 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    2\n",
      "Shape        (3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1., 2.],\n",
    "    [3., 4.], \n",
    "    [5., 6.],\n",
    "    ])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing a value is done simply by indicating its index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The element in the second row and first column:\n",
    "x[1,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rank 3 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]])\n",
      "Type         <class 'torch.Tensor'>\n",
      "dtype        torch.float32\n",
      "Dimension    3\n",
      "Shape        (3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [[1., 2.],[3., 4.]],\n",
    "    [[5., 6.],[7., 8.]],\n",
    "    [[9., 10.],[11., 12.]],\n",
    "    ])\n",
    "h.print_tensor_info(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All elements in the first instances of the first axis:\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2,0,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1,1,1] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.,   2.],\n",
       "         [  3.,   4.]],\n",
       "\n",
       "        [[  5.,   6.],\n",
       "         [  7., 100.]],\n",
       "\n",
       "        [[  9.,  10.],\n",
       "         [ 11.,  12.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Operations\n",
    "\n",
    "There are over 100 tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, and random sampling. The are desribed in are comprehensively described in the [torch pacakge doc](https://pytorch.org/docs/stable/torch.html). Check out the list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-place operations\n",
    "Operations that have a \"`_`\" suffix are in-place. For example: `x.copy_(y)`, ``x.t_()``, will change ``x``.\n",
    "\n",
    "In-place operations save memory by avoiding copynig the data, but cause a loss of history when computing derivatives.\n",
    "\n",
    "Let's look at an in-place addition operation, and compare it to a 'standard' addition (where the result of the operation is stored in a new location in memory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) \n",
      "\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(2, 2)\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)  # notice the underscore\n",
    "print(tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) \n",
      "\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(2, 2)\n",
    "print(tensor, \"\\n\")\n",
    "tensor.add(5)  # no underscore\n",
    "print(tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations below are all \"not-in-place\", and these are usually the operations we will work with."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arithmetic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic is the branch of mathematics that deals with the manipulation of numbers and quantities. It includes the study of basic operations such as addition, subtraction, multiplication, and division, as well as more advanced ones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize two rank-1 tensors first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 2.])\n",
      "y: tensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.])\n",
    "y = torch.tensor([3., 4.])\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four basic operations of arithmetics (addition, subtraction, multiplication and division, as defined by operator overloading) are conducted element-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + y : tensor([4., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(f'x + y : {x + y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x - y : tensor([-2., -2.])\n"
     ]
    }
   ],
   "source": [
    "print(f'x - y : {x - y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x * y : tensor([3., 8.])\n"
     ]
    }
   ],
   "source": [
    "print(f'x * y : {x * y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x / y : tensor([0.3333, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "print(f'x / y : {x / y}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at two foundational operations: the dot product and matric multiplication:\n",
    "#### The dot-product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{u} \\cdot \\textbf{v} = \\sum_i{\\textbf{u}_i \\times \\textbf{v}_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dot(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product is commutative, $\\textbf{u} \\cdot \\textbf{v} = \\textbf{v} \\cdot \\textbf{u}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dot(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2D Example:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "  10 & 20 & 30 \\\\\n",
    "  40 & 50 & 60\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "  2 & 3 & 5 & 7 \\\\\n",
    "  11 & 13 & 17 & 19 \\\\\n",
    "  23 & 29 & 31 & 37\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "  930 & 1160 & 1320 & 1560 \\\\\n",
    "  2010 & 2510 & 2910 & 3450\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $Q$ of size $m \\times n$ can be multiplied by a matrix $R$ of size $n \\times q$. The result $P$ is an $m \\times q$ matrix where each element is computed as a sum of products:\n",
    "\n",
    "$P_{i,j} = \\sum_{k=1}^n{Q_{i,k} \\times R_{k,j}}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element $P_{i,j}$ is the dot product of the row vector $Q_{i,*}$ and the column vector $R_{*,j}$ (!) :\n",
    "\n",
    "$P_{i,j} = Q_{i,*} \\cdot R_{*,j}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Questions\n",
    "1. If we were to define the two matrices in the example above in PyTorch, What would be their shapes?\n",
    "2. Based on this definition, can you write down the calculation that yields `930` in the example above?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `PyTorch`, matrix multiplication is implemented using `torch.matmul`. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1., 2.],[3., 4.]])\n",
    "y = torch.tensor([[5., 6.],[7., 8.]])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [43., 50.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.matmul(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.5 [introduced](https://docs.python.org/3/whatsnew/3.5.html#pep-465-a-dedicated-infix-operator-for-matrix-multiplication) the `@` ('At-sign') operator for matrix multiplication. In PyTorch (and Tensorflow) `@` is an alias of `matmul`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [43., 50.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x@y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `torch.matmul` on tensors with rank!=2\n",
    "`torch.matmul` extends the 2D matrix multiplication to lower and higher dimensions. Its [docstring](https://pytorch.org/docs/stable/generated/torch.matmul.html) is very useful to see how the 2D definition is extended into lower or higher dimensions. In other words, the mathematical operation depends on the rank of the tensors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-D tensors\n",
    "According to the `troch.matmul` [docstring](https://pytorch.org/docs/stable/generated/torch.matmul.html):\n",
    ">If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 2.])\n",
      "y: tensor([3., 4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.])\n",
    "y = torch.tensor([3., 4.])\n",
    "print(f'x: {x}')\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### matmul on 1D and 2D ranked tensors\n",
    "From the docstring:\n",
    ">If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its _dimension_ for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.\n",
    "\n",
    "_prepended: add something to the beginning of something else_\n",
    "\n",
    "An example can be useful:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{bmatrix}\n",
    "  1 \\\\ 2 \\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "  3 & 4 \\\\\n",
    "  5 & 6 \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "  13 \\\\ 16 \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([13., 16.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.])\n",
    "y = torch.tensor([[3., 4.],[5., 6.]])\n",
    "print(x)\n",
    "print(y)\n",
    "print(torch.matmul(x,y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the docstring:\n",
    ">If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\begin{bmatrix}\n",
    "  3 & 4 \\\\\n",
    "  5 & 6 \\\\\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ 2 \\\\\n",
    "\\end{bmatrix}= \n",
    "\\begin{bmatrix}\n",
    "  11 \\\\ 17 \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.])\n",
    "y = torch.tensor([[3., 4.],[5., 6.]])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 17.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(y,x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matmul when at least one tensor's rank is > 2\n",
    "In this case a batched matrix multiply is returned, using [boardcasting](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics). See the matmul [docstring](https://pytorch.org/docs/stable/generated/torch.matmul.html) for examples. We will go over broadcasting in the Tensorflow's tensors tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
